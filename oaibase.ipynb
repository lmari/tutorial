{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I più semplici esempi di interazione con modelli locali via l'API di OpenAI\n",
    "\n",
    "Luca Mari, maggio 2025  \n",
    "\n",
    "Quest'opera è distribuita con <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0\" target=\"_blank\">Licenza Creative Commons Attribuzione - Non commerciale - Condividi allo stesso modo 4.0 Internazionale</a>.  \n",
    "<img src=\"https://creativecommons.it/chapterIT/wp-content/uploads/2021/01/by-nc-sa.eu_.png\" width=\"100\">\n",
    "\n",
    "**Obiettivo**: comprendere le più semplice modalità di interazione con modelli locali via l'API di OpenAI.  \n",
    "**Precompetenze**: basi di Python.\n",
    "\n",
    "> Per eseguire questo notebook con VSCode sul proprio calcolatore, occorre:\n",
    "> * installare un interprete Python\n",
    "> * attivare un server locale che renda possibile l'interazione con un modello via l'API di OpenAI (per semplicità, supporremo che sia LM Studio, scaricabile da https://lmstudio.ai)\n",
    "> * scaricare da https://code.visualstudio.com/download e installare VSCode\n",
    "> * eseguire VSCode e attivare le estensioni per Python e Jupyter\n",
    "> * ancora in VSCode:\n",
    ">     * creare una cartella di lavoro e renderla la cartella corrente\n",
    ">     * copiare nella cartella il file di questa attività: [oaibase.ipynb](oaibase.ipynb)\n",
    ">     * aprire il notebook `oaibase.ipynb`\n",
    ">     * creare un ambiente virtuale locale Python (Select Kernel | Python Environments | Create Python Environment | Venv, e scegliere un interprete Python):\n",
    ">     * installare i moduli Python richiesti, eseguendo dal terminale:  \n",
    ">         `pip install openai`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importiamo i moduli Python necessari, definiamo alcune funzioni di utilità, e specifichiamo l'_end point_ per l'accesso al server locale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pprint import pprint\n",
    "from IPython.display import Markdown, display\n",
    "import json\n",
    "\n",
    "def stream_print(response, max_length=100):\n",
    "    length = 0\n",
    "    for chunk in response:\n",
    "        text = chunk.choices[0].delta\n",
    "        if hasattr(text, 'content') and text.content:\n",
    "            print(text.content, end='', flush=True)\n",
    "            length += len(text.content)\n",
    "            if length > max_length:\n",
    "                print()\n",
    "                length = 0\n",
    "\n",
    "def print_markdown(response):\n",
    "    display(Markdown(response))\n",
    "\n",
    "def stream_print_markdown(response):\n",
    "    buffer = \"\"\n",
    "    for chunk in response:\n",
    "        text = chunk.choices[0].delta\n",
    "        if hasattr(text, 'content') and text.content:\n",
    "            buffer += text.content\n",
    "            display(Markdown(buffer), clear=True)\n",
    "\n",
    "\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"...\") # usa un server locale, per esempio con LM Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elenco dei modelli disponibili\n",
    "Assumendo che il server sia attivo, questo è il più semplice esempio di una richiesta al server via l'API di OpenAI, per ottenere la lista dei modelli accessibili attraverso il server stesso (ma in effetti dunque anche per accertare che il server sia accessibile)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model(id='gemma-3-4b-it', created=None, object='model', owned_by='organization_owner'),\n",
      " Model(id='qwen3-30b-a3b', created=None, object='model', owned_by='organization_owner'),\n",
      " Model(id='qwen3-4b', created=None, object='model', owned_by='organization_owner'),\n",
      " Model(id='text-embedding-nomic-embed-text-v1.5@q4_k_m', created=None, object='model', owned_by='organization_owner'),\n",
      " Model(id='gemma-3-12b-it', created=None, object='model', owned_by='organization_owner'),\n",
      " Model(id='qwen2.5-7b-instruct-1m', created=None, object='model', owned_by='organization_owner'),\n",
      " Model(id='ministral-4b-instruct', created=None, object='model', owned_by='organization_owner'),\n",
      " Model(id='gemma-3-27b-it', created=None, object='model', owned_by='organization_owner'),\n",
      " Model(id='qwen2.5-32b-instruct', created=None, object='model', owned_by='organization_owner'),\n",
      " Model(id='qwq-32b', created=None, object='model', owned_by='organization_owner'),\n",
      " Model(id='simplescaling_s1.1-32b', created=None, object='model', owned_by='organization_owner'),\n",
      " Model(id='openthinker-32b', created=None, object='model', owned_by='organization_owner'),\n",
      " Model(id='deepseek-r1-distill-qwen-32b', created=None, object='model', owned_by='organization_owner'),\n",
      " Model(id='deepseek-r1-distill-qwen-1.5b', created=None, object='model', owned_by='organization_owner'),\n",
      " Model(id='deepseek-r1-distill-llama-8b', created=None, object='model', owned_by='organization_owner'),\n",
      " Model(id='deepseek-r1-distill-qwen-7b', created=None, object='model', owned_by='organization_owner'),\n",
      " Model(id='phi-4', created=None, object='model', owned_by='organization_owner'),\n",
      " Model(id='text-embedding-granite-embedding-278m-multilingual', created=None, object='model', owned_by='organization_owner'),\n",
      " Model(id='text-embedding-nomic-embed-text-v1.5@q8_0', created=None, object='model', owned_by='organization_owner'),\n",
      " Model(id='text-embedding-nomic-embed-text-v1.5@f32', created=None, object='model', owned_by='organization_owner')]\n"
     ]
    }
   ],
   "source": [
    "models = client.models.list()\n",
    "pprint(models.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generazione di sentence embedding\n",
    "Assumendo che sia stato caricato un modello di _embedding_ sul server (per esempio `text-embedding-nomic-embed-text-v1.5@f32`), possiamo usarlo per fare _sentence embedding_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La frase è stata codificata in un vettore di 768 numeri;\n",
      "i primi 5 sono: [0.10395540297031403, 0.050489071756601334, -0.0963636264204979, 0.011676624417304993, -0.04801320657134056]\n"
     ]
    }
   ],
   "source": [
    "text = \"La bellezza salverà il mondo.\"\n",
    "\n",
    "response = client.embeddings.create(\n",
    "    model=\"...\",\n",
    "    input=[text]\n",
    ").data[0].embedding\n",
    "\n",
    "print(f'''La frase è stata codificata in un vettore di {len(response)} numeri;\n",
    "i primi 5 sono: {response[:5]}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completion\n",
    "Questo è il più semplice esempio di una richiesta al server via l'API di OpenAI (stiamo supponendo che il server sia attivo e sia stato caricato un modello, per esempio `gemma-3-4b-it`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'intero oggetto JSON di risposta:\n",
      "\n",
      "{'choices': [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Sono Gemma, un modello linguistico di grandi dimensioni creato dal team di Google DeepMind. Sono un'intelligenza artificiale addestrata per comunicare e generare testo simile a quello umano. Sono un modello open-weight, il che significa che sono ampiamente disponibile al pubblico.\\n\\nCome posso aiutarti oggi?\\n\", refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))],\n",
      " 'created': 1746359909,\n",
      " 'id': 'chatcmpl-43758hv5xunu6lvb5e9nyl',\n",
      " 'model': 'gemma-3-4b-it',\n",
      " 'object': 'chat.completion',\n",
      " 'service_tier': None,\n",
      " 'stats': {},\n",
      " 'system_fingerprint': 'gemma-3-4b-it',\n",
      " 'usage': CompletionUsage(completion_tokens=67, prompt_tokens=27, total_tokens=94, completion_tokens_details=None, prompt_tokens_details=None)}\n",
      "\n",
      "Il messaggio generato:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Sono Gemma, un modello linguistico di grandi dimensioni creato dal team di Google DeepMind. Sono un'intelligenza artificiale addestrata per comunicare e generare testo simile a quello umano. Sono un modello open-weight, il che significa che sono ampiamente disponibile al pubblico.\n",
       "\n",
       "Come posso aiutarti oggi?\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"Presentati: chi sei?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"...\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Rispondi sempre in italiano. /no_think\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    max_tokens=-1,\n",
    "    temperature=2,\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "print(\"L'intero oggetto JSON di risposta:\\n\")\n",
    "pprint(dict(response))\n",
    "\n",
    "print(\"\\nIl messaggio generato:\")\n",
    "print_markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completion con stream dei token\n",
    "Quasi identica all'esempio precedente è la richiesta di una risposta che sia inviata un token per volta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Ciao! Sono **un modello linguistico di grandi dimensioni**, creato da Google. In pratica, sono un'**intelligenza artificiale** progettata per comprendere e generare testo. Posso rispondere a domande, tradurre lingue, scrivere diversi tipi di contenuti creativi e molto altro ancora. Sono ancora in fase di **sviluppo**, ma imparo continuamente nuove informazioni e migliorando le mie capacità. \n",
       "\n",
       "Cosa posso fare per te oggi?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"Presentati: chi sei? (metti in grassetto le parole chiave)\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"...\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Rispondi sempre in italiano.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    max_tokens=-1,\n",
    "    temperature=0.7,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "stream_print_markdown(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completion con interpretazione del contenuto di un'immagine\n",
    "Se sul server è attivo un modello multimodale appropriato (per esempio `gemma-3-27b-it` -- modelli della serie `gemma-3` con un minor numero di parametri non funzionano...), la richiesta può includere l'URL di un'immagine e si può chiedere al modello di interpretare il contenuto dell'immagine stessa. In tal caso, per prima cosa occorre convertire l'immagine in formato base64.  \n",
    "Visualizziamo anche l'immagine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/a/aa/Fingandslide.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "from IPython.display import Image as IPImage\n",
    "\n",
    "url = \"https://upload.wikimedia.org/wikipedia/commons/a/aa/Fingandslide.jpg\"\n",
    "\n",
    "def get_image_and_convert_to_base64(url):\n",
    "    response = requests.get(url)\n",
    "    image = Image.open(BytesIO(response.content))\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format=\"PNG\")\n",
    "    return \"data:image/png;base64,\" + base64.b64encode(buffer.getvalue()).decode()\n",
    "\n",
    "image_base64 = get_image_and_convert_to_base64(url)\n",
    "\n",
    "IPImage(url=url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si può ora inviare la richiesta al modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certo, ecco una descrizione di ciò che vedo nell'immagine:\n",
       "\n",
       "L'immagine mostra un primo piano delle mani di qualcuno che suona una chitarra resofonica (spesso chiamata \"dobro\"). Ecco i dettagli principali:\n",
       "\n",
       "*   **Chitarra:** La chitarra è argentata e ha una forma particolare, con dei fori circolari e a goccia sul corpo. Si tratta chiaramente di uno strumento risonante, come si evince dal cono metallico visibile all'interno del corpo della chitarra.\n",
       "*   **Tecnica:** La persona sta suonando la chitarra usando una tecnica chiamata \"slide guitar\".  Si può vedere un cilindro nero (il \"slide\") attorno a uno delle dita della mano sinistra, che viene fatto scorrere lungo le corde per ottenere un suono caratteristico e glissato.\n",
       "*   **Plettro:** La mano destra sta pizzicando le corde con un plettro.\n",
       "*   **Abbigliamento:** La persona indossa una maglia nera e pantaloni grigi.\n",
       "\n",
       "In generale, l'immagine suggerisce un musicista che suona uno strumento particolare e con una tecnica specifica, probabilmente in ambito blues o country."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"...\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Rispondi sempre in italiano.\"},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"image_url\", \"image_url\": { \"url\": image_base64 }},\n",
    "            {\"type\": \"text\", \"text\": \"Descrivi cosa vedi\"}\n",
    "        ]}\n",
    "    ],\n",
    "    max_tokens=-1,\n",
    "    temperature=0.7,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "stream_print_markdown(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completion con structured output\n",
    "Solo un poco più complessa è una richiesta in cui si specifica lo schema JSON che vogliamo sia utilizzato nella risposta, nuovamente in accordo all'API di OpenAI, nella specifica _structured output_ (https://platform.openai.com/docs/guides/structured-outputs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"nome\": \"Gemini\",\n",
      "  \"produttore\": \"Google\",\n",
      "  \"caratteristiche principali\": \"Sono un modello lingu\n",
      "istico di grandi dimensioni, addestrato da Google. Posso comunicare e generare testo simile a quello umano\n",
      " in risposta a una vasta gamma di prompt e domande. Sono ancora in fase di sviluppo, ma imparo cose nuove\n",
      " ogni giorno.\"\n",
      "    ,\n",
      "  \"caratteristiche secondarie\": \"Posso tradurre lingue, scrivere diversi tipi di\n",
      " contenuti creativi e rispondere alle tue domande in modo informativo. Cerco sempre di fornire risposte\n",
      " accurate e complete, ma a volte potrei commettere errori.\"\n",
      "}\n",
      " \t \t \t \t \t \t \t \t \t \t"
     ]
    }
   ],
   "source": [
    "response_format = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"presentazione\",\n",
    "        \"strict\": \"true\",\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"nome\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Il tuo nome\"\n",
    "                },\n",
    "                \"produttore\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Il nome del tuo produttore\",\n",
    "                    \"enum\": [\"OpenAI\", \"Google\", \"Meta\", \"other\"]\n",
    "                },\n",
    "                \"caratteristiche principali\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Le tue caratteristiche principali\"\n",
    "                },\n",
    "                \"caratteristiche secondarie\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Le tue caratteristiche secondarie\"\n",
    "                }\n",
    "            },\n",
    "        \"required\": [\"nome\", \"produttore\", \"caratteristiche principali\", \"caratteristiche secondarie\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "prompt = \"Presentati: chi sei?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"...\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Rispondi sempre in italiano.\" },\n",
    "        {\"role\": \"user\", \"content\": prompt }\n",
    "    ],\n",
    "    max_tokens=-1,\n",
    "    temperature=0.7,\n",
    "    stream=True,\n",
    "    response_format=response_format # type: ignore\n",
    ")\n",
    "\n",
    "stream_print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function calling\n",
    "\n",
    "Ancora una volta in accordo all'API di OpenAI, un caso particolare di _structured output_ è il _function calling_ (https://platform.openai.com/docs/guides/function-calling), in cui lo schema JSON specifica una lista di funzioni, da trattare appunto come strumenti che possono essere usati.  \n",
    "Data la maggiore complessità di questo caso, sviluppiamo con qualche dettaglio un esempio.\n",
    "\n",
    "Supponendo di voler ottenere informazioni dal database della World Bank, e di volerlo fare con una chiamata alla sua API (qui qualche informazione al proposito: https://datahelpdesk.worldbank.org/knowledgebase/articles/898581-api-basic-call-structures), la struttura del sistema sarebbe come in questo diagramma:\n",
    "\n",
    "![schema](oaibase.drawio.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La richiesta: https://api.worldbank.org/v2/country/it/indicator/SP.URB.TOTL?date=2021&format=json\n",
      "\n",
      "La risposta:\n",
      "[{'lastupdated': '2025-04-15',\n",
      "  'page': 1,\n",
      "  'pages': 1,\n",
      "  'per_page': 50,\n",
      "  'sourceid': '2',\n",
      "  'total': 1},\n",
      " [{'country': {'id': 'IT', 'value': 'Italy'},\n",
      "   'countryiso3code': 'ITA',\n",
      "   'date': '2021',\n",
      "   'decimal': 0,\n",
      "   'indicator': {'id': 'SP.URB.TOTL', 'value': 'Urban population'},\n",
      "   'obs_status': '',\n",
      "   'unit': '',\n",
      "   'value': 42189154}]]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "request = \"https://api.worldbank.org/v2/country/it/indicator/SP.URB.TOTL?date=2021&format=json\"\n",
    "response = requests.get(request).json()\n",
    "\n",
    "print(f\"La richiesta: {request}\")\n",
    "print(\"\\nLa risposta:\")\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non è difficile elaborare il JSON della risposta per produrre un risultato più leggibile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paese: Italy\n",
      "Popolazione: 42189154\n"
     ]
    }
   ],
   "source": [
    "print(f\"Paese: {response[1][0]['country']['value']}\")\n",
    "print(f\"Popolazione: {response[1][0]['value']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ma rimane il fatto che la richiesta deve essere inviata rispettando il formato specificato nella API della World Bank.  \n",
    "Possiamo però usare un modello di linguaggio, a cui porre richieste in italiano, e facendo il modo che queste richieste vengano opportunamente tradotte e quindi eseguite come chiamate all'API, costruendo un sistema più complesso:\n",
    "\n",
    "![schema2](oaibase2.drawio.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo strumento per inviare richieste all'API è in questo caso una semplice funzione Python, insieme con una sua descrizione JSON che consenta al modello di linguaggio di conoscere il nome della funzione e i suoi argomenti. In questo modo, l'oggetto JSON che il modello di linguaggio genera, in risposta a una richiesta che riceve, dovrebbe contenere l'informazione per eseguire la funzione, e quindi inviare all'API la richiesta nel formato opportuno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WB_API_call(countries: list[str], date: str) -> list:\n",
    "    result = []\n",
    "    for country in countries:\n",
    "        response = requests.get(f\"https://api.worldbank.org/v2/country/{country}/indicator/SP.URB.TOTL?date={date}&format=json\")\n",
    "        result.append(response.json())\n",
    "    return result\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"WB_API_call\",\n",
    "            \"description\": \"Ottieni informazioni dal database della World Bank via API\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"countries\": {\n",
    "                        \"type\": \"list\",\n",
    "                        \"description\": \"Il codice ISO dei Paesi di cui si vogliono ottenere i dati\"\n",
    "                    },\n",
    "                    \"date\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"L'anno di riferimento\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"countries\", \"date\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il modello di linguaggio opera perciò come traduttore, da richieste dell'utente formulate in italiano, a JSON per chiamare lo strumento (da cui il termine _function calling_). Vediamone un esempio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='273265957', function=Function(arguments='{\"countries\":[\"IT\"],\"date\":\"2021\"}', name='WB_API_call'), type='function')]))],\n",
      " 'created': 1746360791,\n",
      " 'id': 'chatcmpl-tvzg6mspo34ywzfmogvn',\n",
      " 'model': 'gemma-3-4b-it',\n",
      " 'object': 'chat.completion',\n",
      " 'service_tier': None,\n",
      " 'stats': {},\n",
      " 'system_fingerprint': 'gemma-3-4b-it',\n",
      " 'usage': CompletionUsage(completion_tokens=42, prompt_tokens=479, total_tokens=521, completion_tokens_details=None, prompt_tokens_details=None)}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Ottieni dal database della World Bank i dati relativi alla popolazione urbana dell'Italia' nel 2021.\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"...\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Rispondi sempre in italiano.\" },\n",
    "        {\"role\": \"user\", \"content\": prompt }\n",
    "    ],\n",
    "    max_tokens=-1,\n",
    "    temperature=0.7,\n",
    "    tools=tools # type: ignore\n",
    ")\n",
    "\n",
    "pprint(dict(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dato che il formato di questo JSON è standard, la funzione per eseguire lo strumento specificato con gli argomenti specificati è generica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_tool(response, with_log=False):\n",
    "    if with_log:\n",
    "        print(\"L'intero oggetto JSON di risposta:\")\n",
    "        pprint(dict(response))\n",
    "        print(\"\\nIl messaggio generato:\")\n",
    "        pprint(response.choices[0].message)\n",
    "\n",
    "    if response.choices[0].message.tool_calls:\n",
    "        tool_call = response.choices[0].message.tool_calls[0]\n",
    "\n",
    "        if with_log:\n",
    "            print(\"\\nLa parte del messaggio riferita alla funzione da chiamare:\")\n",
    "            print(tool_call.function)\n",
    "\n",
    "        function_name = tool_call.function.name\n",
    "        function_arguments = json.loads(tool_call.function.arguments)\n",
    "        \n",
    "        if with_log:\n",
    "            pprint(f\"\\nLa funzione da chiamare è: {function_name}; i suoi argomenti sono: {function_arguments}\")\n",
    "\n",
    "        result = globals()[function_name](**function_arguments)\n",
    "\n",
    "        if with_log:\n",
    "            pprint(f\"\\nIl risultato della funzione è: {result}\")\n",
    "\n",
    "        return result\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ed ecco finalmente un esempio di _function calling_ completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'intero oggetto JSON di risposta:\n",
      "{'choices': [Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='792641581', function=Function(arguments='{\"countries\":[\"BR\",\"AR\",\"CL\",\"PY\",\"VE\",\"EC\",\"BO\"],\"date\":\"2019\"}', name='WB_API_call'), type='function')]))],\n",
      " 'created': 1746360809,\n",
      " 'id': 'chatcmpl-4jjviafd9uikdx1w243vlg',\n",
      " 'model': 'gemma-3-4b-it',\n",
      " 'object': 'chat.completion',\n",
      " 'service_tier': None,\n",
      " 'stats': {},\n",
      " 'system_fingerprint': 'gemma-3-4b-it',\n",
      " 'usage': CompletionUsage(completion_tokens=60, prompt_tokens=481, total_tokens=541, completion_tokens_details=None, prompt_tokens_details=None)}\n",
      "\n",
      "Il messaggio generato:\n",
      "ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='792641581', function=Function(arguments='{\"countries\":[\"BR\",\"AR\",\"CL\",\"PY\",\"VE\",\"EC\",\"BO\"],\"date\":\"2019\"}', name='WB_API_call'), type='function')])\n",
      "\n",
      "La parte del messaggio riferita alla funzione da chiamare:\n",
      "Function(arguments='{\"countries\":[\"BR\",\"AR\",\"CL\",\"PY\",\"VE\",\"EC\",\"BO\"],\"date\":\"2019\"}', name='WB_API_call')\n",
      "('\\n'\n",
      " \"La funzione da chiamare è: WB_API_call; i suoi argomenti sono: {'countries': \"\n",
      " \"['BR', 'AR', 'CL', 'PY', 'VE', 'EC', 'BO'], 'date': '2019'}\")\n",
      "('\\n'\n",
      " \"Il risultato della funzione è: [[{'page': 1, 'pages': 1, 'per_page': 50, \"\n",
      " \"'total': 1, 'sourceid': '2', 'lastupdated': '2025-04-15'}, [{'indicator': \"\n",
      " \"{'id': 'SP.URB.TOTL', 'value': 'Urban population'}, 'country': {'id': 'BR', \"\n",
      " \"'value': 'Brazil'}, 'countryiso3code': 'BRA', 'date': '2019', 'value': \"\n",
      " \"180121128, 'unit': '', 'obs_status': '', 'decimal': 0}]], [{'page': 1, \"\n",
      " \"'pages': 1, 'per_page': 50, 'total': 1, 'sourceid': '2', 'lastupdated': \"\n",
      " \"'2025-04-15'}, [{'indicator': {'id': 'SP.URB.TOTL', 'value': 'Urban \"\n",
      " \"population'}, 'country': {'id': 'AR', 'value': 'Argentina'}, \"\n",
      " \"'countryiso3code': 'ARG', 'date': '2019', 'value': 41371540, 'unit': '', \"\n",
      " \"'obs_status': '', 'decimal': 0}]], [{'page': 1, 'pages': 1, 'per_page': 50, \"\n",
      " \"'total': 1, 'sourceid': '2', 'lastupdated': '2025-04-15'}, [{'indicator': \"\n",
      " \"{'id': 'SP.URB.TOTL', 'value': 'Urban population'}, 'country': {'id': 'CL', \"\n",
      " \"'value': 'Chile'}, 'countryiso3code': 'CHL', 'date': '2019', 'value': \"\n",
      " \"16825479, 'unit': '', 'obs_status': '', 'decimal': 0}]], [{'page': 1, \"\n",
      " \"'pages': 1, 'per_page': 50, 'total': 1, 'sourceid': '2', 'lastupdated': \"\n",
      " \"'2025-04-15'}, [{'indicator': {'id': 'SP.URB.TOTL', 'value': 'Urban \"\n",
      " \"population'}, 'country': {'id': 'PY', 'value': 'Paraguay'}, \"\n",
      " \"'countryiso3code': 'PRY', 'date': '2019', 'value': 4031453, 'unit': '', \"\n",
      " \"'obs_status': '', 'decimal': 0}]], [{'page': 1, 'pages': 1, 'per_page': 50, \"\n",
      " \"'total': 1, 'sourceid': '2', 'lastupdated': '2025-04-15'}, [{'indicator': \"\n",
      " \"{'id': 'SP.URB.TOTL', 'value': 'Urban population'}, 'country': {'id': 'VE', \"\n",
      " \"'value': 'Venezuela, RB'}, 'countryiso3code': 'VEN', 'date': '2019', \"\n",
      " \"'value': 25534978, 'unit': '', 'obs_status': '', 'decimal': 0}]], [{'page': \"\n",
      " \"1, 'pages': 1, 'per_page': 50, 'total': 1, 'sourceid': '2', 'lastupdated': \"\n",
      " \"'2025-04-15'}, [{'indicator': {'id': 'SP.URB.TOTL', 'value': 'Urban \"\n",
      " \"population'}, 'country': {'id': 'EC', 'value': 'Ecuador'}, \"\n",
      " \"'countryiso3code': 'ECU', 'date': '2019', 'value': 11095186, 'unit': '', \"\n",
      " \"'obs_status': '', 'decimal': 0}]], [{'page': 1, 'pages': 1, 'per_page': 50, \"\n",
      " \"'total': 1, 'sourceid': '2', 'lastupdated': '2025-04-15'}, [{'indicator': \"\n",
      " \"{'id': 'SP.URB.TOTL', 'value': 'Urban population'}, 'country': {'id': 'BO', \"\n",
      " \"'value': 'Bolivia'}, 'countryiso3code': 'BOL', 'date': '2019', 'value': \"\n",
      " \"8143476, 'unit': '', 'obs_status': '', 'decimal': 0}]]]\")\n",
      "[[{'lastupdated': '2025-04-15',\n",
      "   'page': 1,\n",
      "   'pages': 1,\n",
      "   'per_page': 50,\n",
      "   'sourceid': '2',\n",
      "   'total': 1},\n",
      "  [{'country': {'id': 'BR', 'value': 'Brazil'},\n",
      "    'countryiso3code': 'BRA',\n",
      "    'date': '2019',\n",
      "    'decimal': 0,\n",
      "    'indicator': {'id': 'SP.URB.TOTL', 'value': 'Urban population'},\n",
      "    'obs_status': '',\n",
      "    'unit': '',\n",
      "    'value': 180121128}]],\n",
      " [{'lastupdated': '2025-04-15',\n",
      "   'page': 1,\n",
      "   'pages': 1,\n",
      "   'per_page': 50,\n",
      "   'sourceid': '2',\n",
      "   'total': 1},\n",
      "  [{'country': {'id': 'AR', 'value': 'Argentina'},\n",
      "    'countryiso3code': 'ARG',\n",
      "    'date': '2019',\n",
      "    'decimal': 0,\n",
      "    'indicator': {'id': 'SP.URB.TOTL', 'value': 'Urban population'},\n",
      "    'obs_status': '',\n",
      "    'unit': '',\n",
      "    'value': 41371540}]],\n",
      " [{'lastupdated': '2025-04-15',\n",
      "   'page': 1,\n",
      "   'pages': 1,\n",
      "   'per_page': 50,\n",
      "   'sourceid': '2',\n",
      "   'total': 1},\n",
      "  [{'country': {'id': 'CL', 'value': 'Chile'},\n",
      "    'countryiso3code': 'CHL',\n",
      "    'date': '2019',\n",
      "    'decimal': 0,\n",
      "    'indicator': {'id': 'SP.URB.TOTL', 'value': 'Urban population'},\n",
      "    'obs_status': '',\n",
      "    'unit': '',\n",
      "    'value': 16825479}]],\n",
      " [{'lastupdated': '2025-04-15',\n",
      "   'page': 1,\n",
      "   'pages': 1,\n",
      "   'per_page': 50,\n",
      "   'sourceid': '2',\n",
      "   'total': 1},\n",
      "  [{'country': {'id': 'PY', 'value': 'Paraguay'},\n",
      "    'countryiso3code': 'PRY',\n",
      "    'date': '2019',\n",
      "    'decimal': 0,\n",
      "    'indicator': {'id': 'SP.URB.TOTL', 'value': 'Urban population'},\n",
      "    'obs_status': '',\n",
      "    'unit': '',\n",
      "    'value': 4031453}]],\n",
      " [{'lastupdated': '2025-04-15',\n",
      "   'page': 1,\n",
      "   'pages': 1,\n",
      "   'per_page': 50,\n",
      "   'sourceid': '2',\n",
      "   'total': 1},\n",
      "  [{'country': {'id': 'VE', 'value': 'Venezuela, RB'},\n",
      "    'countryiso3code': 'VEN',\n",
      "    'date': '2019',\n",
      "    'decimal': 0,\n",
      "    'indicator': {'id': 'SP.URB.TOTL', 'value': 'Urban population'},\n",
      "    'obs_status': '',\n",
      "    'unit': '',\n",
      "    'value': 25534978}]],\n",
      " [{'lastupdated': '2025-04-15',\n",
      "   'page': 1,\n",
      "   'pages': 1,\n",
      "   'per_page': 50,\n",
      "   'sourceid': '2',\n",
      "   'total': 1},\n",
      "  [{'country': {'id': 'EC', 'value': 'Ecuador'},\n",
      "    'countryiso3code': 'ECU',\n",
      "    'date': '2019',\n",
      "    'decimal': 0,\n",
      "    'indicator': {'id': 'SP.URB.TOTL', 'value': 'Urban population'},\n",
      "    'obs_status': '',\n",
      "    'unit': '',\n",
      "    'value': 11095186}]],\n",
      " [{'lastupdated': '2025-04-15',\n",
      "   'page': 1,\n",
      "   'pages': 1,\n",
      "   'per_page': 50,\n",
      "   'sourceid': '2',\n",
      "   'total': 1},\n",
      "  [{'country': {'id': 'BO', 'value': 'Bolivia'},\n",
      "    'countryiso3code': 'BOL',\n",
      "    'date': '2019',\n",
      "    'decimal': 0,\n",
      "    'indicator': {'id': 'SP.URB.TOTL', 'value': 'Urban population'},\n",
      "    'obs_status': '',\n",
      "    'unit': '',\n",
      "    'value': 8143476}]]]\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Ottieni dal database della World Bank i dati relativi alla popolazione urbana delle nazioni del Sud America nel 2019.\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"...\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Rispondi sempre in italiano.\" },\n",
    "        {\"role\": \"user\", \"content\": prompt }\n",
    "    ],\n",
    "    max_tokens=-1,\n",
    "    temperature=0.7,\n",
    "    tools=tools # type: ignore\n",
    ")\n",
    "\n",
    "final_response = exec_tool(response, with_log=True)\n",
    "pprint(final_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E la funzione che estrae i dati rilevanti dalla lista ottenuta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'country': 'Brazil', 'population': 180121128},\n",
       " {'country': 'Argentina', 'population': 41371540},\n",
       " {'country': 'Chile', 'population': 16825479},\n",
       " {'country': 'Paraguay', 'population': 4031453},\n",
       " {'country': 'Venezuela, RB', 'population': 25534978},\n",
       " {'country': 'Ecuador', 'population': 11095186},\n",
       " {'country': 'Bolivia', 'population': 8143476}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def post_process_WB_API_call(response: list) -> list:\n",
    "    result = []\n",
    "    for country_response in response:\n",
    "        country = country_response[1][0]['country']['value']\n",
    "        population = country_response[1][0]['value']\n",
    "        result.append({\"country\": country, \"population\": population})\n",
    "    return result\n",
    "\n",
    "post_process_WB_API_call(final_response) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo è dunque l'esempio completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'country': 'Brazil', 'population': 180121128},\n",
       " {'country': 'Argentina', 'population': 41371540},\n",
       " {'country': 'Chile', 'population': 16825479},\n",
       " {'country': 'Paraguay', 'population': 4031453},\n",
       " {'country': 'Venezuela, RB', 'population': 25534978},\n",
       " {'country': 'Ecuador', 'population': 11095186},\n",
       " {'country': 'Bolivia', 'population': 8143476}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Ottieni dal database della World Bank i dati relativi alla popolazione urbana delle nazioni del Sud America nel 2019.\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"...\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Rispondi sempre in italiano.\" },\n",
    "        {\"role\": \"user\", \"content\": prompt }\n",
    "    ],\n",
    "    max_tokens=-1,\n",
    "    temperature=0.7,\n",
    "    tools=tools # type: ignore\n",
    ")\n",
    "\n",
    "post_process_WB_API_call(exec_tool(response)) # type: ignore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
