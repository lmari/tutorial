{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L'approssimazione di una funzione lineare mediante un singolo neurone a comportamento lineare\n",
    "\n",
    "Luca Mari, gennaio 2025  \n",
    "\n",
    "Quest'opera è distribuita con <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0\" target=\"_blank\">Licenza Creative Commons Attribuzione - Non commerciale - Condividi allo stesso modo 4.0 Internazionale</a>.  \n",
    "<img src=\"https://creativecommons.it/chapterIT/wp-content/uploads/2021/01/by-nc-sa.eu_.png\" width=\"100\">\n",
    "\n",
    "**Obiettivo**: comprendere, a partire da un esempio concreto, che una rete neurale deve includere degli elementi non lineari per poter approssimare appropriatamente anche delle semplici funzioni non lineari.  \n",
    "**Precompetenze**: basi di Python; almeno qualche idea di analisi matematica.\n",
    "\n",
    "> Per eseguire questo notebook, supponiamo con VSCode, occorre:\n",
    "> * installare un interprete Python\n",
    "> * scaricare da https://code.visualstudio.com/download e installare VSCode\n",
    "> * eseguire VSCode e attivare le estensioni per Python e Jupyter\n",
    "> * ancora in VSCode:\n",
    ">     * creare una cartella di lavoro e renderla la cartella corrente\n",
    ">     * copiare nella cartella il file di questa attività: [neuron.ipynb](neuron.ipynb)\n",
    ">     * aprire il notebook `neuron.ipynb`\n",
    ">     * creare un ambiente virtuale locale Python (Select Kernel | Python Environments | Create Python Environment | Venv, e scegliere un interprete Python):\n",
    ">     * installare il modulo Python richiesto, eseguendo dal terminale:  \n",
    ">         `pip install torch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una rete neurale è l'implementazione di una funzione parametrica $Y = f(X; K)$, e può essere intesa come uno strumento di approssimazione di funzioni $F(X)$ date: attraverso un opportuno addestramento, si trovano i valori appropriati dei parametri $K$ in modo che $f(X; K) \\approx F(X)$.\n",
    "\n",
    "Quest'idea venne sviluppata inizialmente assumendo che i componenti elementari di una rete -- i suoi neuroni -- avessero un comportamento lineare:  \n",
    "\n",
    "![rete](neuron.drawio.svg)  \n",
    "nel caso di due input.\n",
    "\n",
    "La situazione più semplice è ovviamente quella di una rete costituita da un solo neurone. Facciamo qualche prova.\n",
    "\n",
    "Per costruire e operare sulla rete useremo `PyTorch`: importiamo perciò i moduli Python che saranno necessari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Costruiamo la rete usando `PyTorch` (il codice ha un po' di dettagli tecnici, non necessariamente importanti: i commenti potrebbero essere comunque utili) e visualizziamo i valori dei suoi parametri, che inizialmente sono casuali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I parametri della rete sono:\n",
      "neuron.weight tensor([[ 0.4909, -0.6757]])\n",
      "neuron.bias tensor([-0.2738])\n"
     ]
    }
   ],
   "source": [
    "class OneNeuron(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OneNeuron, self).__init__()\n",
    "        self.neuron = nn.Linear(2, 1)\n",
    "\n",
    "        self.loss = nn.MSELoss()        # funzione di errore: Mean Squared Error\n",
    "        self.optimizer = optim.SGD(self.parameters(), lr=0.01) # ottimizzatore: Stochastic Gradient Descent # type: ignore\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.neuron(x)\n",
    "        return x\n",
    "\n",
    "    def set_learning_rate(self, learning_rate):\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = learning_rate        \n",
    "\n",
    "    def train(self, x, y, epochs, repeat):\n",
    "        print(f'\\n*** Addestramento ***\\nepoca\\terrore)')\n",
    "        for epoch in range(epochs):\n",
    "            self.optimizer.zero_grad()  # azzera i gradienti\n",
    "            output = self(x)            # calcola l'output\n",
    "            loss = self.loss(output, y) # calcola la funzione di errore\n",
    "            loss.backward()             # calcola i gradienti\n",
    "            self.optimizer.step()       # aggiorna i valori dei parametri\n",
    "            if (epoch+1) % repeat == 0:\n",
    "                print(f'{epoch+1}\\t{loss.item():.3f}')\n",
    "\n",
    "    def predict(self, examples, fun):\n",
    "        print('\\n*** Inferenza ***')\n",
    "        x_test = examples\n",
    "        y_test = self(x_test)           # calcola la previsione\n",
    "        y_true = self.calc_fun(fun, x_test)\n",
    "        print('x1\\tx2\\ty\\ty prev\\terrore')\n",
    "        for i in range(x_test.size(0)):\n",
    "            x1, x2 = x_test[i][0].item(), x_test[i][1].item()\n",
    "            y, y_hat = y_true[i].item(), y_test[i].item()\n",
    "            print(f'{x1:.2f}\\t{x2:.2f}\\t{y:.2f}\\t{y_hat:.2f}\\t{y - y_hat:.2f}')\n",
    "        print(f'Errore quadratico medio: {torch.mean((y_test - y_true)**2):.5f}')\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for layer in self.children():\n",
    "            if hasattr(layer, 'reset_parameters'):\n",
    "                layer.reset_parameters()\n",
    "\n",
    "    def print_parameters(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            print(name, param.data)\n",
    "\n",
    "    def calc_fun(self, fun, X):\n",
    "        return fun(X[:, 0], X[:, 1]).view(-1, 1)\n",
    "\n",
    "\n",
    "model = OneNeuron()\n",
    "print('I parametri della rete sono:'); model.print_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Costruiamo il training set, prima di tutto negli input (_features_, _covariates_) come un certo numero di coppie di numeri casuali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def examples(n): return (10 * torch.rand(n, 2) - 5) # genera n esempi nella forma ognuno di una coppia di numeri casuali tra -5 e 5\n",
    "num_examples = 100                      # numero di esempi per il training set\n",
    "X = examples(num_examples)              # calcola i valori degli esempi: input del training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scegliamo la funzione, dunque a due argomenti, da approssimare. Essendo un caso di _supervised learning_, calcoliamo la funzione per tutte le coppie del training set e aggiungiamo il risultato al training set stesso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'esempio di una tripla nel training set: x1=1.02, x2=-4.57, y=-1.77\n"
     ]
    }
   ],
   "source": [
    "def fun(x1, x2): return (x1 + x2) / 2   # funzione da approssimare, in questo caso la media tra due numeri\n",
    "Y = model.calc_fun(fun, X)              # calcola il valore della funzione per ogni esempio: output del training set\n",
    "i = random.randint(0, num_examples-1)   # indice casuale\n",
    "print(f\"L'esempio di una tripla nel training set: x1={X[i, 0].item():.2f}, x2={X[i, 1].item():.2f}, y={Y[i, 0].item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Già ora possiamo mettere in funzione la rete, su un certo numero di esempi che costituiscono dunque un test set, ma ovviamente il risultato non sarà in alcun modo accurato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Inferenza ***\n",
      "x1\tx2\ty\ty prev\terrore\n",
      "3.83\t-3.28\t0.27\t3.82\t-3.55\n",
      "2.72\t-1.99\t0.36\t2.41\t-2.05\n",
      "-0.49\t2.20\t0.86\t-2.00\t2.86\n",
      "3.98\t-1.00\t1.49\t2.35\t-0.86\n",
      "-0.17\t4.99\t2.41\t-3.73\t6.14\n",
      "-1.56\t3.85\t1.14\t-3.64\t4.78\n",
      "1.05\t-3.57\t-1.26\t2.65\t-3.91\n",
      "-3.77\t-0.79\t-2.28\t-1.59\t-0.69\n",
      "-2.65\t2.44\t-0.11\t-3.23\t3.12\n",
      "3.42\t-2.48\t0.47\t3.08\t-2.61\n",
      "Errore quadratico medio: 11.86144\n"
     ]
    }
   ],
   "source": [
    "model.predict(examples(10), fun)        # inferenza prima dell'addestramento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addestriamo allora la rete, dopo aver assegnato valori opportuni ai due iperparametri fondamentali:  \n",
    "-- il numero di volte in cui il processo di addestramento viene ripetuto, e  \n",
    "-- la velocità di apprendimento (_learning rate_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Addestramento ***\n",
      "epoca\terrore)\n",
      "10\t0.141\n",
      "20\t0.062\n",
      "30\t0.028\n",
      "40\t0.012\n",
      "50\t0.006\n",
      "60\t0.002\n",
      "70\t0.001\n",
      "80\t0.000\n",
      "90\t0.000\n",
      "100\t0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucamari/Bin/tutorial/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:823: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100                        # numero di ripetizioni del processo di addestramento\n",
    "repeat = 10                             # numero di ripetizioni dopo le quali visualizzare l'errore\n",
    "model.reset_parameters()                # reinizializza i parametri della rete\n",
    "model.set_learning_rate(0.02)           # imposta il learning rate\n",
    "model.train(X, Y, num_epochs, repeat)   # addestra la rete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mettiamo in funzione la rete su un nuovo test set: se l'addestramento ha avuto successo, si dovrebbe ottenere un piccolo errore quadratico medio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Inferenza ***\n",
      "x1\tx2\ty\ty prev\terrore\n",
      "-1.65\t0.11\t-0.77\t-0.76\t-0.01\n",
      "3.80\t3.68\t3.74\t3.75\t-0.01\n",
      "-2.48\t-1.38\t-1.93\t-1.92\t-0.01\n",
      "-2.31\t-1.88\t-2.10\t-2.09\t-0.01\n",
      "-3.64\t4.79\t0.58\t0.59\t-0.01\n",
      "4.17\t-0.34\t1.91\t1.92\t-0.01\n",
      "1.62\t-2.67\t-0.52\t-0.51\t-0.01\n",
      "1.06\t-4.45\t-1.69\t-1.68\t-0.01\n",
      "-2.98\t0.58\t-1.20\t-1.19\t-0.01\n",
      "2.10\t-2.12\t-0.01\t0.00\t-0.01\n",
      "Errore quadratico medio: 0.00010\n"
     ]
    }
   ],
   "source": [
    "model.predict(examples(10), fun)        # inferenza dopo l'addestramento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizziamo i valori dei parametri della rete: se l'addestramento ha avuto successo, dovrebbero essere vicini ai valori attesi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuron.weight tensor([[0.5004, 0.4998]])\n",
      "neuron.bias tensor([0.0096])\n"
     ]
    }
   ],
   "source": [
    "model.print_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La struttura della rete è così semplice che possiamo ripetere l'intero processo senza ricorrere a `PyTorch`, per mostrare così in modo esplicito la logica della procedura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Addestramento ***\n",
      "epoca\terrore\tk0\tk1\tk2\n",
      "10\t3.272\t-0.897\t0.202\t0.541\n",
      "20\t0.396\t-0.747\t0.408\t0.589\n",
      "30\t0.371\t-0.615\t0.475\t0.526\n",
      "40\t0.249\t-0.503\t0.480\t0.522\n",
      "50\t0.163\t-0.411\t0.481\t0.516\n",
      "60\t0.117\t-0.335\t0.499\t0.497\n",
      "70\t0.078\t-0.274\t0.498\t0.503\n",
      "80\t0.040\t-0.225\t0.480\t0.510\n",
      "90\t0.029\t-0.186\t0.484\t0.505\n",
      "100\t0.028\t-0.152\t0.498\t0.505\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100                        # numero di ripetizioni del processo di addestramento\n",
    "repeat = 10                             # numero di ripetizioni dopo le quali visualizzare l'errore\n",
    "learning_rate = 0.01                    # learning rate\n",
    "minibatch_size = 10                     # dimensione del minibatch: numero di esempi estratti dal training set per ogni epoca\n",
    "\n",
    "k0, k1, k2 = torch.randn(3)             # valori casuali di inizializzazione dei parametri \n",
    "\n",
    "print(f'\\n*** Addestramento ***\\nepoca\\terrore\\tk0\\tk1\\tk2')\n",
    "for i in range(num_epochs):\n",
    "    indexes = torch.randperm(X.size(0))[:minibatch_size]            # seleziona in modo casuale gli indici del minibatch\n",
    "    X1 = X[indexes, 0]                                              # estrai dal training set gli argomenti della funzione\n",
    "    X2 = X[indexes, 1]\n",
    "    Y_prev = k0 + k1 * X1 + k2 * X2                                 # calcola la previsione\n",
    "    Y_true = Y[indexes, 0]                                          # estrai dal training set il valore della funzione\n",
    "    loss = torch.mean((Y[indexes, 0] - Y_prev)**2)                  # calcola la funzione di errore (errore quadratico medio)\n",
    "    k0 -= learning_rate * 2 * torch.mean(Y_prev - Y_true)           # calcola le derivate parziali della funzione di errore...\n",
    "    k1 -= learning_rate * 2 * torch.mean((Y_prev - Y_true) * X1)    # ... e aggiorna i valori dei parametri...\n",
    "    k2 -= learning_rate * 2 * torch.mean((Y_prev - Y_true) * X2)    # ... dunque \"scendendo lungo il gradiente\"\n",
    "    if (i+1) % repeat == 0:\n",
    "        print(f'{i+1}\\t{loss.item():.3f}\\t{k0:.3f}\\t{k1:.3f}\\t{k2:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quella che segue è invece un'implementazione semplificata di un algoritmo genetico, per risolvere lo stesso problema di ottimizzazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Addestramento ***\n",
      "epoca\terrore\tk0\tk1\tk2\n",
      "10\t0.043\t-0.200\t0.453\t0.568\n",
      "20\t0.146\t-0.200\t0.395\t0.446\n",
      "30\t0.081\t-0.257\t0.466\t0.668\n",
      "40\t0.134\t-0.289\t0.540\t0.525\n",
      "50\t0.009\t-0.050\t0.534\t0.501\n",
      "60\t0.018\t-0.097\t0.598\t0.501\n",
      "70\t0.100\t-0.257\t0.497\t0.428\n",
      "80\t0.057\t-0.033\t0.662\t0.459\n",
      "90\t0.057\t-0.347\t0.406\t0.411\n",
      "100\t0.085\t0.922\t0.519\t0.431\n"
     ]
    }
   ],
   "source": [
    "num_individuals = 100                   # numero di individui della popolazione in evoluzione\n",
    "num_survivors = 50                      # numero di individui che in ogni epoca sopravvive\n",
    "num_mutations = 5                       # numero di individui che in ogni epoca subisce una mutazione \n",
    "width_mutations = .1                    # ampiezza (deviazione standard) delle mutazioni\n",
    "minibatch_size = 10                     # dimensione del minibatch: numero di esempi estratti dal training set per ogni epoca\n",
    "num_epochs = 100                        # numero di ripetizioni del processo di addestramento\n",
    "repeat = 10                             # numero di ripetizioni dopo le quali visualizzare l'errore\n",
    "\n",
    "k = torch.randn(num_individuals, 3)\n",
    "\n",
    "print(f'\\n*** Addestramento ***\\nepoca\\terrore\\tk0\\tk1\\tk2')\n",
    "for i in range(num_epochs):\n",
    "    indexes = torch.randperm(X.size(0))[:minibatch_size]            # seleziona in modo casuale gli indici del minibatch\n",
    "    X1 = X[indexes, 0].view(-1, 1).T                                # estrai dal training set gli argomenti della funzione\n",
    "    X2 = X[indexes, 1].view(-1, 1).T\n",
    "    Y_true = Y[indexes, 0].view(-1, 1).T                            # estrai dal training set il valore della funzione\n",
    "    Y_prev = k[:,0].view(-1, 1) + k[:,1].view(-1, 1) * X1 + k[:,2].view(-1, 1) * X2 # calcola la previsione\n",
    "\n",
    "    loss = torch.mean((Y[indexes, 0] - Y_prev)**2, dim=1)           # calcola la funzione di errore per ogni individuo\n",
    "    sorted_indexes = torch.argsort(loss, descending=False)          # ottieni gli indici degli individui ordinati in base all'errore\n",
    "    k = k[sorted_indexes][:num_survivors]                           # ordina gli individui per fitness e seleziona i migliori\n",
    "\n",
    "    m0 = torch.randint(num_survivors, (num_mutations, 1)).view(-1)  # seleziona casualmente gli indici degli individui da mutare\n",
    "    m1 = torch.randint(3, (num_mutations, 1)).view(-1)\n",
    "    k[m0, m1] += torch.randn(num_mutations) * width_mutations       # introduci una mutazione negli individui selezionati\n",
    "\n",
    "    k = torch.cat((k, torch.randn(num_individuals - num_survivors, 3)), 0) # reintegra la popolazione con nuovi individui casuali\n",
    "\n",
    "    if (i+1) % repeat == 0:\n",
    "        best = k[sorted_indexes][0]\n",
    "        print(f'{i+1}\\t{loss[sorted_indexes][0].item():.3f}\\t{best[0].item():.3f}\\t{best[1].item():.3f}\\t{best[2].item():.3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tornando ora a usare `PyTorch`: d'altra parte, è evidente che un singolo neurone a comportamento lineare può approssimare efficacemente solo funzioni molto semplici. Anche aumentando il numero di esempi e di ripetizioni del processo di addestramento, per esempio non è in grado di approssimare in modo accettabile la funzione massimo tra due numeri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Addestramento ***\n",
      "epoca\terrore)\n",
      "100\t1.491\n",
      "200\t1.413\n",
      "300\t1.411\n",
      "400\t1.411\n",
      "500\t1.411\n",
      "600\t1.411\n",
      "700\t1.411\n",
      "800\t1.411\n",
      "900\t1.411\n",
      "1000\t1.411\n",
      "\n",
      "*** Inferenza ***\n",
      "x1\tx2\ty\ty prev\terrore\n",
      "0.66\t0.07\t0.66\t2.06\t-1.40\n",
      "-4.36\t-0.82\t-0.82\t-0.91\t0.09\n",
      "-1.24\t-2.52\t-1.24\t-0.21\t-1.03\n",
      "-4.02\t-2.73\t-2.73\t-1.71\t-1.02\n",
      "-1.26\t-1.79\t-1.26\t0.15\t-1.41\n",
      "0.26\t3.94\t3.94\t3.83\t0.11\n",
      "0.90\t2.30\t2.30\t3.31\t-1.01\n",
      "-1.82\t-2.16\t-1.82\t-0.32\t-1.50\n",
      "1.40\t1.20\t1.40\t3.01\t-1.61\n",
      "4.66\t-3.45\t4.66\t2.27\t2.39\n",
      "Errore quadratico medio: 1.76398\n"
     ]
    }
   ],
   "source": [
    "num_examples = 1000                     # numero di esempi per il training set\n",
    "X = examples(num_examples)              # input del training set\n",
    "def fun(x1, x2): return torch.max(x1, x2) # funzione da approssimare, in questo caso il massimo tra due numeri\n",
    "Y = model.calc_fun(fun, X)              # calcola il valore della funzione per ogni esempio: output del training set\n",
    "num_epochs = 1000                       # numero di ripetizioni del processo di addestramento\n",
    "repeat = 100                            # numero di ripetizioni dopo le quali visualizzare l'errore\n",
    "model.reset_parameters()                # reinizializza i parametri della rete\n",
    "model.set_learning_rate(0.01)           # imposta il learning rate\n",
    "model.train(X, Y, num_epochs, repeat)   # addestra la rete\n",
    "model.predict(examples(10), fun)        # metti in funzione la rete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per ottenere approssimazioni accettabili occorre dunque costruire una rete più complessa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
