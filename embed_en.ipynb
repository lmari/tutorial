{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An exploration of *token embedding* with a transformer\n",
    "\n",
    "Luca Mari, January 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary has 30522 tokens.\n",
      "Each token is associated to (embedded in) a vector of 1024 numbers.\n"
     ]
    }
   ],
   "source": [
    "import _keys\n",
    "from tokenizeutils import Model\n",
    "from pprint import pprint\n",
    "\n",
    "model = Model('google-bert/bert-large-uncased', False)\n",
    "\n",
    "print(f\"The vocabulary has {model.vocab_size} tokens.\")\n",
    "print(f\"Each token is associated to (embedded in) a vector of {model.embedding_dim} numbers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token 'library' has the identifier 3075\n",
      "(To any token not in the vocabulary the identifier 100 is associated).\n"
     ]
    }
   ],
   "source": [
    "token = \"library\"\n",
    "token_id = model.token_to_id(token)\n",
    "unknown_token_id = model.tokenizer.convert_tokens_to_ids(model.tokenizer.unk_token) # type: ignore\n",
    "\n",
    "if token_id is not unknown_token_id:\n",
    "    print(f\"The token '{token}' has the identifier {token_id}\")\n",
    "else:\n",
    "    print(f\"The token '{token}' is not in the vocabulary.\")\n",
    "print(f\"(To any token not in the vocabulary the identifier {model.tokenizer.convert_tokens_to_ids(model.tokenizer.unk_token)} is associated).\") # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il modello è stato addestrato a mappare (_to embed_, appunto) ogni token, con il suo identificatore, in una successione di numeri (c'è da considerare che i transformer, come `BERT`, operano sulla base di un embedding dinamico, in cui la successione di numeri associata a ogni token dipende anche dal contesto ('embedding posizionale'): qui noi lavoriamo solo con la componente statica del mapping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token 'library' is associated to a vector of 1024 elements whose first 5 elements are:\n",
      "[-0.02522797 -0.02368372 -0.04366647 -0.00486308 -0.00388711]\n"
     ]
    }
   ],
   "source": [
    "embedding = model.token_to_embedding(token)\n",
    "print(f\"The token '{token}' is associated to a vector of {len(embedding)} elements whose first 5 elements are:\\n{embedding[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The 10 tokens most similar to 'library' in the vocabulary:\n",
      "[('libraries', 0.67),\n",
      " ('librarian', 0.53),\n",
      " ('archives', 0.41),\n",
      " ('bookstore', 0.4),\n",
      " ('museum', 0.4),\n",
      " ('archive', 0.39),\n",
      " ('collection', 0.34),\n",
      " ('database', 0.34),\n",
      " ('bibliography', 0.33),\n",
      " ('repository', 0.33)]\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "print(f\"\\nThe {n} tokens most similar to '{token}' in the vocabulary:\")\n",
    "pprint(model.most_similar(token, top_n=n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.57)]\n"
     ]
    }
   ],
   "source": [
    "positive_examples = [\"king\", \"woman\"]\n",
    "negative_examples = [\"man\"]\n",
    "pprint(model.combine_meanings(positive_examples, negative_examples, top_n=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('madrid', 0.42)]\n"
     ]
    }
   ],
   "source": [
    "positive_examples = [\"Rome\", \"Spain\"]\n",
    "negative_examples = [\"Italy\"]\n",
    "print(model.combine_meanings(positive_examples, negative_examples, top_n=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('winter', 0.48)]\n"
     ]
    }
   ],
   "source": [
    "positive_examples = [\"summer\", \"cold\"] \n",
    "negative_examples = [\"warm\"]\n",
    "print(model.combine_meanings(positive_examples, negative_examples, top_n=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('piano', 0.62)]\n"
     ]
    }
   ],
   "source": [
    "positive_examples = [\"guitar\", \"pianist\"]\n",
    "negative_examples = [\"guitarist\"]\n",
    "print(model.combine_meanings(positive_examples, negative_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mother', 0.62)]\n"
     ]
    }
   ],
   "source": [
    "positive_examples = [\"father\", \"daughter\"]\n",
    "negative_examples = [\"son\"]\n",
    "print(model.combine_meanings(positive_examples, negative_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('actress', 0.73)]\n"
     ]
    }
   ],
   "source": [
    "positive_examples = [\"actor\", \"woman\"]\n",
    "negative_examples = [\"man\"]\n",
    "print(model.combine_meanings(positive_examples, negative_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('good', 0.46)]\n"
     ]
    }
   ],
   "source": [
    "positive_examples = [\"fine\", \"bad\"]\n",
    "negative_examples = [\"ugly\"]\n",
    "print(model.combine_meanings(positive_examples, negative_examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se i precedenti sono esempi ricchi semanticamente, proviamo a sperimentare anche con esempi solo grammaticali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('automobile', 0.61)]\n"
     ]
    }
   ],
   "source": [
    "positive_examples = [\"train\", \"automobiles\"]\n",
    "negative_examples = [\"trains\"]\n",
    "print(model.combine_meanings(positive_examples, negative_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('see', 0.48)]\n"
     ]
    }
   ],
   "source": [
    "positive_examples = [\"go\", \"seen\"]\n",
    "negative_examples = [\"gone\"]\n",
    "print(model.combine_meanings(positive_examples, negative_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('listening', 0.63)]\n"
     ]
    }
   ],
   "source": [
    "positive_examples = [\"thinking\", \"listen\"]\n",
    "negative_examples = [\"think\"]\n",
    "print(model.combine_meanings(positive_examples, negative_examples))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
